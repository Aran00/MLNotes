---
title: "07. Multiple Classes"
date: 2016-08-18 21:08\\\\\\\\
---

[TOC]

###多分类学习
#### 拆分策略
多分类学习的基本思路是 “拆解法”,即将多分类任务拆为若干个二分类任务求解

最经典的拆分策略有三种:

- “一对一” （One vs.One,简称OvO)
- “一对其余” （One vs.Rest,简称 OvR)
- “多对多” （Many vs.Many,简称 MvM)

给定数据集$D=\{(\boldsymbol x_1, y_1),(\boldsymbol x_2, y_2),\cdots,(\boldsymbol x_m, y_m)\}, y_i \in \{C_1,C_2,\cdots,C_N\}$

- OvO将这iV个类别两两配对,从而产生N(N-1)/2个二分类任务
  	- 例如OvO将为区分类别$C_i$和$C_j$训练一个分类器,该分类器把$D$中的$C_i$类样例作为正例, $C_j$的类样例作为反例。
  	- 在测试阶段,新样本将同时提交给所有分类器,于是我们将得到N(N-1)/2个分类结果,最终结果可通过投票产生。
- OvR则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练N个分类器
  - 测试时若仅有一个分类器预测为正类,则对应的类别标记作为最终分类结果；
  - 若有多个分类器预测为正类,则通常考虑各分类器的预测置信度,选择置信度最大的类别标记作为分类结果.
- MvM是每次将若干个类作为正类,若干个其他类作为反类.MvM的正、反类构造必须有特殊的设计, 不能随意选取.
  - 常用技术：纠错输出码(ECOC)
  
OvO和OvR的比较：

- OvR只需训练N个分类器,而OvO需训练N(N-1)/2个分类器,因此,OvO的存储开销和测试时间开销通常比OvR更大.
- 但在训练时,OvR的每个分类器均使用全部训练样例,而OvO的每个分类器仅用到两个类的样例,因此,在类别很多时,OvO的训练时间开销通常比OvR更小•

### OVR具体实现
使用Softmax function
$$p(c_k|x) = y_k(x) = \frac{exp(a_k)}{\sum_j exp(a_j)}$$
其中$a_k=\beta_k^Tx$。

从贝叶斯推断的角度，这个式子可以解释为：
$$p(c_k|x) = \frac{p(x|c_k)p(c_k)}{\sum_j p(x|c_j)p(c_j)} = \frac{exp(a_k)}{\sum_j exp(a_j)}$$
即
$$a_k = ln(p(x|c_k)p(c_k))$$
也可以使用IRLS方法进行训练。